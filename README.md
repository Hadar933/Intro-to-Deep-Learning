# Intro to Deep Learning
## summary
check out my `IDL_notes.pdf` lecture notes! if you'd rather not download the file, check the `google drive` link [HERE](https://drive.google.com/file/d/1zVkw5lkE8bqBvSb5qZ4zdJX1pPC-F758/view?usp=sharing), or either one of those `linked-in` discussions [1](https://www.linkedin.com/posts/rami-krispin_deeplearning-datascience-datascientist-activity-6870814994032918528-3Pr6)/[2](https://www.linkedin.com/posts/michael-mike-erlihson-phd-8208616_intro-to-deep-learning-huji-activity-6870981392914755584-zZ6O)

Chapters recap:
| Chapter                          |   Sections recap                                               | 
| ---------------------------------|:--------------------------------------------------------------:|
| Basic NN model                   |  MLP, Activations, Loss function, Backpropagation              |
| deep NN theory                   |  Universal Approximation Thm., Shallow vs deep                 |
| LTI systems and Convolutional-NN |    Time/Translation Invariance, Convolutional NN               |  
| Rerurrent-NN                     | Elman network, Backpropagation through time, LSTM, GRU         |  
| Attention Layers                 | Attention, self Attention, Multi-head Attention, Transformers  |  
| Auto-Encoders                    | Auto-Encoders, VAE, WAE                                        |   
| Generative Models                | GAN, cGAN, GLOW, GLO                                          |   
| Optimizations                    | Sharp/Smooth minima, Momentum, AdaGrad, Adam                   |   



## Exercises
| Exercise                          |   Description                                                                                                                      | 
| ----|:----------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| ex1 |  implementing **MLP** to identify peptides from the Spike protein of the SARS-CoV-2 virus                                                                        |
| ex2 | comparing **Elman network** (basic RNN), **GRU cell**, and **MLP** with **restricted self-attention layer** in classifying movie reviews as positive or negative |
| ex3 |     using **GAN** and conditional GAN (**cGAN**) to generate novel samples of the MNIST dataset                                                                  |  

